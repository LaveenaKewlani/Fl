{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eDW1lGz0JLPx"
   },
   "source": [
    "# FL Vanilla Mode using syft\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jfsSUzsHHhcw"
   },
   "source": [
    "**Author** \n",
    ": Laveena Kewlani\n",
    "\n",
    "**Objective** : To run a decentralized model uisng MNIST dataset on FL vanilla architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "0gXPFf6zVT61",
    "outputId": "9db63e89-d366-4bd7-9429-5ece7fc28516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -mpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -mpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution - (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -mpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -mpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution - (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "Requirement already satisfied: syft in /opt/anaconda3/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: sympy==1.9 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (1.9)\n",
      "Requirement already satisfied: typing-extensions==4.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (4.0.0)\n",
      "Requirement already satisfied: pydantic[email]==1.8.2 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (1.8.2)\n",
      "Requirement already satisfied: requests-toolbelt==0.9.1 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (0.9.1)\n",
      "Requirement already satisfied: autodp==0.2 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (0.2)\n",
      "Requirement already satisfied: pyarrow==6.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (6.0.0)\n",
      "Requirement already satisfied: requests==2.26.0 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (2.26.0)\n",
      "Requirement already satisfied: names==0.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (0.3.0)\n",
      "Requirement already satisfied: numpy==1.21.4 in /Users/a844410yara.com/.local/lib/python3.8/site-packages (from syft) (1.21.4)\n",
      "Requirement already satisfied: ascii-magic==1.6 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (1.6)\n",
      "Requirement already satisfied: tqdm==4.62.3 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (4.62.3)\n",
      "Requirement already satisfied: packaging==21.2 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (21.2)\n",
      "Requirement already satisfied: loguru==0.5.3 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (0.5.3)\n",
      "Requirement already satisfied: forbiddenfruit==0.1.4 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (0.1.4)\n",
      "Requirement already satisfied: SQLAlchemy==1.4.27 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (1.4.27)\n",
      "Requirement already satisfied: pandas==1.3.4 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (1.3.4)\n",
      "Requirement already satisfied: PyJWT==2.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (2.3.0)\n",
      "Requirement already satisfied: werkzeug==2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (2.0.2)\n",
      "Requirement already satisfied: gevent==21.8.0 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (21.8.0)\n",
      "Requirement already satisfied: bcrypt==3.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (3.2.0)\n",
      "Requirement already satisfied: importlib-metadata==4.8.2 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (4.8.2)\n",
      "Requirement already satisfied: cachetools==4.2.4 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (4.2.4)\n",
      "Requirement already satisfied: pymbolic==2021.1 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (2021.1)\n",
      "Requirement already satisfied: protobuf==3.19.1 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (3.19.1)\n",
      "Requirement already satisfied: torch<=1.10.0,>=1.8.1 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (1.10.0)\n",
      "Requirement already satisfied: PyNaCl==1.4.0 in /opt/anaconda3/lib/python3.8/site-packages (from syft) (1.4.0)\n",
      "Requirement already satisfied: colorama in /opt/anaconda3/lib/python3.8/site-packages (from ascii-magic==1.6->syft) (0.4.4)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.8/site-packages (from ascii-magic==1.6->syft) (8.4.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.8/site-packages (from autodp==0.2->syft) (1.6.2)\n",
      "Requirement already satisfied: six>=1.4.1 in /opt/anaconda3/lib/python3.8/site-packages (from bcrypt==3.2.0->syft) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.1 in /opt/anaconda3/lib/python3.8/site-packages (from bcrypt==3.2.0->syft) (1.15.0)\n",
      "Requirement already satisfied: zope.event in /opt/anaconda3/lib/python3.8/site-packages (from gevent==21.8.0->syft) (4.5.0)\n",
      "Requirement already satisfied: zope.interface in /opt/anaconda3/lib/python3.8/site-packages (from gevent==21.8.0->syft) (5.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.8/site-packages (from gevent==21.8.0->syft) (58.0.4)\n",
      "Requirement already satisfied: greenlet<2.0,>=1.1.0 in /opt/anaconda3/lib/python3.8/site-packages (from gevent==21.8.0->syft) (1.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.8/site-packages (from importlib-metadata==4.8.2->syft) (3.7.0)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from packaging==21.2->syft) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas==1.3.4->syft) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/lib/python3.8/site-packages (from pandas==1.3.4->syft) (2.8.2)\n",
      "Requirement already satisfied: email-validator>=1.0.3 in /opt/anaconda3/lib/python3.8/site-packages (from pydantic[email]==1.8.2->syft) (1.1.3)\n",
      "Requirement already satisfied: pytools>=2 in /opt/anaconda3/lib/python3.8/site-packages (from pymbolic==2021.1->syft) (2022.1.2)\n",
      "Requirement already satisfied: pytest>=2.3 in /opt/anaconda3/lib/python3.8/site-packages (from pymbolic==2021.1->syft) (6.2.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests==2.26.0->syft) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests==2.26.0->syft) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests==2.26.0->syft) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from requests==2.26.0->syft) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.8/site-packages (from sympy==1.9->syft) (1.2.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.1->bcrypt==3.2.0->syft) (2.21)\n",
      "Requirement already satisfied: dnspython>=1.15.0 in /opt/anaconda3/lib/python3.8/site-packages (from email-validator>=1.0.3->pydantic[email]==1.8.2->syft) (2.2.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from pytest>=2.3->pymbolic==2021.1->syft) (21.4.0)\n",
      "Requirement already satisfied: iniconfig in /opt/anaconda3/lib/python3.8/site-packages (from pytest>=2.3->pymbolic==2021.1->syft) (1.1.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/anaconda3/lib/python3.8/site-packages (from pytest>=2.3->pymbolic==2021.1->syft) (1.0.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/anaconda3/lib/python3.8/site-packages (from pytest>=2.3->pymbolic==2021.1->syft) (1.11.0)\n",
      "Requirement already satisfied: toml in /opt/anaconda3/lib/python3.8/site-packages (from pytest>=2.3->pymbolic==2021.1->syft) (0.10.2)\n",
      "Requirement already satisfied: platformdirs>=2.2.0 in /opt/anaconda3/lib/python3.8/site-packages (from pytools>=2->pymbolic==2021.1->syft) (2.5.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -mpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -mpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution - (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -mpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -mpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution - (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -mpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -umpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -mpy (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution - (/opt/anaconda3/lib/python3.8/site-packages)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Reference : https://pypi.org/project/syft/\n",
    "#\n",
    "!pip install syft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Subset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import syft as sy\n",
    "import helper\n",
    "\n",
    "#Hooking syft to torch\n",
    "hook = sy.TorchHook(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGQj7JfPZSil"
   },
   "outputs": [],
   "source": [
    "#Method to create 10 virtual workers and move to a list of workers\n",
    "def create_workers():\n",
    "  workers = []\n",
    "  cartman = sy.VirtualWorker(hook, id = \"cartman\")\n",
    "  workers.append(cartman)\n",
    "  kyle = sy.VirtualWorker(hook, id = \"kyle\")\n",
    "  workers.append(kyle)\n",
    "  kenny = sy.VirtualWorker(hook, id = \"kenny\")\n",
    "  workers.append(kenny)\n",
    "  stan = sy.VirtualWorker(hook, id = \"stan\")\n",
    "  workers.append(stan)\n",
    "  butters = sy.VirtualWorker(hook, id = \"butters\")\n",
    "  workers.append(butters)\n",
    "  wendy = sy.VirtualWorker(hook, id = \"wendy\")\n",
    "  workers.append(wendy)\n",
    "  heidi = sy.VirtualWorker(hook, id = \"heidi\")\n",
    "  workers.append(heidi)\n",
    "  bebe = sy.VirtualWorker(hook, id = \"bebe\")\n",
    "  workers.append(bebe)\n",
    "  nichole = sy.VirtualWorker(hook, id = \"nichole\")\n",
    "  workers.append(nichole)\n",
    "  patty = sy.VirtualWorker(hook, id = \"patty\")\n",
    "  workers.append(patty)\n",
    "  return workers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8_vP_5qrFfpe"
   },
   "outputs": [],
   "source": [
    "#Method to clear out every tensor stored in the list of virtual workers\n",
    "def clear_workers(workers):\n",
    "  for worker in workers:\n",
    "    worker.clear_objects()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MpF-MD4EW_ON"
   },
   "outputs": [],
   "source": [
    "#Method to split the mnist test dataset into the various workers and also to load the mnist test dataset into a test loader\n",
    "def create_federated_and_test_loaders(workers, trainset, testset):\n",
    "  federated_train_loader = sy.FederatedDataLoader(\n",
    "      trainset.federate(workers), \n",
    "      batch_size=32, shuffle=True)\n",
    "\n",
    "  test_loader = th.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "  return federated_train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8xAwKFm9Vp0"
   },
   "outputs": [],
   "source": [
    "#Method to train models on the virtual workers without moving any gradient to the central models until the gradients have been coallated.\n",
    "def create_train_federated_models(workers, loader, lr = 0.12, epoch = 5):\n",
    "  #sends model to first virtual worker\n",
    "  virtual_model = classifier().send(workers[0])\n",
    "  optimizer = optim.SGD(virtual_model.parameters(), lr)\n",
    "  criterion = nn.NLLLoss()\n",
    "  for n in range(epoch):\n",
    "    \n",
    "    #Integer to keep up with first index.\n",
    "    i = 0\n",
    "    \n",
    "    #Integer to keep up with current worker while training\n",
    "    j = 0\n",
    "    \n",
    "    #Integer to count number of mini-batches per worker\n",
    "    n_mbatch = 0\n",
    "    \n",
    "    #Variable to keep up with current worker while looping\n",
    "    dbLoc = None\n",
    "    \n",
    "    #Variable to store cummulative loss.\n",
    "    cum_loss = 0\n",
    "    \n",
    "    \n",
    "    for batch_idx, (imgs, labels) in enumerate(loader):\n",
    "      \n",
    "      #condition to set dbLoc to the first worker\n",
    "      if i == 0:\n",
    "        i = 2\n",
    "        dbLoc = imgs.location\n",
    "        \n",
    "      #condition to change dbLoc if img is stored on a different worker and also calculate loss\n",
    "      if dbLoc is not imgs.location:\n",
    "        print(\"The total loss for {0} for epoch {2} is {1}\".format(workers[j].id, cum_loss / n_mbatch, n+1))\n",
    "        dbLoc = imgs.location\n",
    "        j += 1\n",
    "        \n",
    "        #Moving the model to a new worker\n",
    "        virtual_model.move(dbLoc)\n",
    "        \n",
    "        #Resetting the cummulative loss and batch count to zero for new worker\n",
    "        cum_loss = 0\n",
    "        n_mbatch = 0\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "      output = virtual_model.forward(imgs)\n",
    "      loss = criterion(output, labels)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      cum_loss +=  loss.get().item()\n",
    "      n_mbatch += 1\n",
    "    print(\"The total loss for {0} is {1}\".format(workers[j].id, cum_loss / n_mbatch))\n",
    "    \n",
    "    #Moving the model to the first worker if training would occur again\n",
    "    if (n < (epoch - 1)):\n",
    "      virtual_model.move(workers[0])\n",
    "  return virtual_model\n",
    "  \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H4FD2KugTeSn"
   },
   "outputs": [],
   "source": [
    "#Method to return the model to the central machine\n",
    "def create_central_model(model):\n",
    "  return model.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdzoIdyZUOQV"
   },
   "outputs": [],
   "source": [
    "#Method to analyze the private database with the trained model\n",
    "def analyze_model(model, loader):\n",
    "  print(\"Running on \", \"cpu\")\n",
    "  cum_perc = 0\n",
    "  for imgs, labels in loader:\n",
    "    with th.no_grad():\n",
    "      ps =  th.exp(model.forward(imgs))\n",
    "    top_p, top_class = ps.topk(1, dim = 1)\n",
    "    prob = top_class == labels.view(*top_class.shape)\n",
    "    prob = prob.float()\n",
    "    cum_perc += prob.mean().float()\n",
    "  print(\"The accuracy of the model is {0}%\".format((cum_perc / len(loader)) * 100))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fA1Ox2FexyL"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_n/srwlszrj3_zg0x4d3k1h10wh0000gn/T/ipykernel_63617/226701423.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Classifier for creating the models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "#Classifier for creating the models\n",
    "class classifier(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__() \n",
    "    self.fc1 = nn.Linear(784, 256)\n",
    "    self.fc2 = nn.Linear(256, 128)\n",
    "    self.fc3 = nn.Linear(128, 64)\n",
    "    self.fc4 = nn.Linear(64, 32)\n",
    "    self.fc5 = nn.Linear(32, 10)\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = x.view(x.shape[0], -1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = F.relu(self.fc3(x))\n",
    "    x = F.relu(self.fc4(x))\n",
    "    x = F.log_softmax(self.fc5(x), dim = 1)   \n",
    "    return x\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7UiMGYx2Wx9R"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_n/srwlszrj3_zg0x4d3k1h10wh0000gn/T/ipykernel_63617/3578326370.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Application of transforms to normalize the mnist data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m transform = transforms.Compose([transforms.ToTensor(),\n\u001b[0m\u001b[1;32m      3\u001b[0m                                 transforms.Normalize((0.5,), (0.5,))])\n\u001b[1;32m      4\u001b[0m \u001b[0mmnist_trainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmnist_testset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "# Application of transforms to normalize the mnist data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fy7piyUUMUzT"
   },
   "outputs": [],
   "source": [
    "workers = create_workers()\n",
    "clear_workers(workers)\n",
    "federated_loader, test_loader = create_federated_and_test_loaders(workers, mnist_trainset, mnist_testset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "Jl17zwHVWePX",
    "outputId": "1d777500-1f67-4355-9cdc-591e5bdcb263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total loss for cartman for epoch 1 is 1.7833157254660383\n",
      "The total loss for kyle for epoch 1 is 0.9024252550716095\n",
      "The total loss for kenny for epoch 1 is 0.6204849152647435\n",
      "The total loss for stan for epoch 1 is 0.4085380588757231\n",
      "The total loss for butters for epoch 1 is 0.3886932226571631\n",
      "The total loss for wendy for epoch 1 is 0.35908689480671224\n",
      "The total loss for heidi for epoch 1 is 0.3309765687172717\n",
      "The total loss for bebe for epoch 1 is 0.29516828555534497\n",
      "The total loss for nichole for epoch 1 is 0.2855488977375183\n",
      "The total loss for patty is 0.174475033589183\n",
      "The total loss for cartman for epoch 2 is 0.22575426379099806\n",
      "The total loss for kyle for epoch 2 is 0.20347901956832154\n",
      "The total loss for kenny for epoch 2 is 0.2153895103392449\n",
      "The total loss for stan for epoch 2 is 0.17871475322766506\n",
      "The total loss for butters for epoch 2 is 0.18308901988921014\n",
      "The total loss for wendy for epoch 2 is 0.18084254954010248\n",
      "The total loss for heidi for epoch 2 is 0.17430340308458248\n",
      "The total loss for bebe for epoch 2 is 0.17721348134998946\n",
      "The total loss for nichole for epoch 2 is 0.15758031705751063\n",
      "The total loss for patty is 0.10357205752045551\n"
     ]
    }
   ],
   "source": [
    "virtual_model = create_train_federated_models(workers, federated_loader, epoch = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BoVQPxPOT8jQ"
   },
   "outputs": [],
   "source": [
    "central_model = create_central_model(virtual_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LpaY4ULYUbvg",
    "outputId": "b2c5cb82-84fc-4c0d-ade7-7375d6887593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on  cpu\n",
      "The accuracy of the model is 96.1783447265625%\n"
     ]
    }
   ],
   "source": [
    "analyze_model(central_model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FederatedLearning_Project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
